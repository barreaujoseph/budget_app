from scripts.A_traitement_donnees import traiter_fichier_bancaire
from scripts.B_depenses import appliquer_regex, appliquer_fuzzy
import pandas as pd
import re
from openpyxl import load_workbook
import pandas as pd
from rapidfuzz import process, fuzz
from sqlalchemy import text
from db import engine  # Ton objet engine PostgreSQL (depuis db.py)


# ======================================================
# 1. R√©cup√©rer donn√©es postgresql
# 2. Retraiter fichier bancaire
# 3. Appliquer regex et fuzzy
# 4. Concat√©ner 
# 5. Envoyer vers postgresql
# ======================================================

# 1. R√©cup√©rer donn√©es postgresql

print("üì° Connexion √† la base Railway...")
df_remote = pd.read_sql("SELECT * FROM operations;", engine)
print(f"‚úÖ Donn√©es r√©cup√©r√©es : {len(df_remote)} lignes")

# 2. Retraiter fichier bancaire
df_nouveau = traiter_fichier_bancaire("CA20251114_091415.xlsx")
df_nouveau = appliquer_regex(df_nouveau)

# 3. Harmoniser les colonnes
colonnes_communes = list(set(df_remote.columns) & set(df_nouveau.columns))
df_remote_aligne = df_remote[colonnes_communes].copy()
df_nouveau_aligne = df_nouveau[colonnes_communes].copy()

# Filtrer les nouvelles op√©rations (>= date max)
date_max_remote = df_remote_aligne["Date"].max()
print(f"üìÖ Derni√®re date dans df_remote : {date_max_remote.strftime('%d/%m/%Y')}")

df_nouveau_filtre = df_nouveau_aligne[df_nouveau_aligne["Date"] >= date_max_remote]
print(f"üÜï {len(df_nouveau_filtre)} nouvelles op√©rations √† partir du {date_max_remote.strftime('%d/%m/%Y')}.")

# Fusion des datasets
df_concat = pd.concat([df_remote_aligne, df_nouveau_filtre], ignore_index=True)
print(f"üß© Fusion effectu√©e : {len(df_concat)} lignes totales avant d√©duplication.")

# D√©duplication cibl√©e ‚Äî uniquement sur la date max
mask_date_max = df_concat["Date"] == date_max_remote
df_date_max = df_concat[mask_date_max]

# D√©tecter les doublons uniquement sur cette date
doublons_date_max = df_date_max.duplicated(subset=["Date", "Libell√©", "Montant", "Compte"], keep="first")

# Supprimer uniquement ces doublons
nb_doublons = doublons_date_max.sum()
if nb_doublons > 0:
    print(f"‚ö†Ô∏è {nb_doublons} doublons d√©tect√©s sur la date {date_max_remote.strftime('%d/%m/%Y')}.")
    df_concat = df_concat[~(mask_date_max & doublons_date_max)]
else:
    print("‚úÖ Aucun doublon d√©tect√© sur la date la plus r√©cente.")

print(f"üßπ Apr√®s nettoyage : {len(df_concat)} lignes uniques au total.")

# 7. Appliquer regex
test = appliquer_fuzzy(df_concat)

print(df_nouveau['Traitee'].value_counts())